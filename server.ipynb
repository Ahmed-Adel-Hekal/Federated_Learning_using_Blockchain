{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d71a29-4416-410c-949f-672b78f166cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import web3\n",
    "from web3 import Web3, HTTPProvider\n",
    "import json\n",
    "import json_numpy\n",
    "import ipfs_api as ip\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10ccf5d-dfdc-4bd8-bbf2-8cec07d588de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31baa6d0-f294-42ad-9d18-33323a672b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server : \n",
    "    def __init__(self, user_ids,data_path,epoch):\n",
    "        self.user_id = user_ids ### Each client use it is specific ip to extract it is data from file\n",
    "        self.contract_address = contract_address   ### contract address generated from server\n",
    "        self.trained_model = None  ### to save model\n",
    "        # w3 = Web3(HTTPProvider('http://127.0.0.1:1111'))\n",
    "        self.abi = abi\n",
    "        self.data_path = data_path\n",
    "        self.x_test_user  = 0 \n",
    "        self.epoch = epoch\n",
    "        ####  Creating tmp dir to save data\n",
    "        if not os.path.exists(\"./tmp/\") :\n",
    "            os.mkdir(\"./tmp/\")\n",
    "    \n",
    "    \n",
    "    def load_data(self):\n",
    "        x_ip = pd.read_csv(self.data_path, index_col=0)\n",
    "        encoder = OneHotEncoder(sparse_output=False)\n",
    "        encoder = encoder.fit(np.array(x_ip['Attack_type'].unique()).reshape(-1, 1))\n",
    "        Y = x_ip['Attack_type']\n",
    "        Y = encoder.transform(np.array(Y).reshape(-1, 1))\n",
    "        x_ip.drop(columns=['ip.src_host', 'Attack_label', 'Attack_type'], inplace=True)\n",
    "        int_data = x_ip.select_dtypes(include=int).astype(float).to_numpy()\n",
    "        float_data = x_ip.select_dtypes(include=float).to_numpy()\n",
    "        obj_data = x_ip.select_dtypes(include=bool).astype(float).to_numpy()\n",
    "        x_ip = np.concatenate([float_data, int_data, obj_data], axis=1)\n",
    "        self.x_train_user, self.x_test_user, self.y_train_user, self.y_test_user = train_test_split(\n",
    "            x_ip, Y, test_size=.1, random_state=42)\n",
    "\n",
    "    def preprocess(self):\n",
    "        BATCH_SIZE = 20\n",
    "        SHUFFLE_BUFFER = 100\n",
    "        PREFETCH_BUFFER = 10\n",
    "        self.load_data()\n",
    "        self.x_train_user = tf.convert_to_tensor(self.x_train_user)\n",
    "        data_size = len(self.x_train_user)\n",
    "        # print(len(self.x_train_user))\n",
    "        self.x_test_user = tf.convert_to_tensor(self.x_test_user)\n",
    "        self.y_train_user = tf.convert_to_tensor(self.y_train_user)\n",
    "        self.y_test_user = tf.convert_to_tensor(self.y_test_user)\n",
    "        self.x_train_user = tf.reshape(self.x_train_user, [-1, 46])\n",
    "        self.x_test_user = tf.reshape(self.x_test_user, [-1, 46])\n",
    "        self.y_train_user = tf.reshape(self.y_train_user, [-1, 15])\n",
    "        self.y_test_user = tf.reshape(self.y_test_user, [-1, 15])\n",
    "        self.train_dataset = tf.data.Dataset.from_tensor_slices((self.x_train_user, self.y_train_user))\n",
    "        self.test_dataset = tf.data.Dataset.from_tensor_slices((self.x_test_user, self.y_test_user))\n",
    "        self.train_dataset = self.train_dataset.repeat(3).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(\n",
    "            PREFETCH_BUFFER)\n",
    "        self.test_dataset = self.test_dataset.repeat(3).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(\n",
    "            PREFETCH_BUFFER)\n",
    "\n",
    "\n",
    "    def Model_Arch(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(46, 1)),\n",
    "            tf.keras.layers.Conv1D(64, 2, activation='relu', name='conv1d_1'),\n",
    "            tf.keras.layers.BatchNormalization(name='batch_normalization_1'),\n",
    "            tf.keras.layers.MaxPooling1D(pool_size=2, name='max_pooling1d_1'),\n",
    "            # tf.keras.layers.Conv1D(64, 2, activation='relu', name='conv1d_2'),\n",
    "            # tf.keras.layers.BatchNormalization(name='batch_normalization_2'),\n",
    "            # tf.keras.layers.MaxPooling1D(pool_size=2, name='max_pooling1d_2'),\n",
    "            tf.keras.layers.Conv1D(128, 2, activation='relu', name='conv1d_3'),\n",
    "            tf.keras.layers.BatchNormalization(name='batch_normalization_3'),\n",
    "            tf.keras.layers.Flatten(name='flatten'),\n",
    "            tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='dense_1'),\n",
    "            # tf.keras.layers.Dropout(0.1, name='dropout'),\n",
    "            # tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='dense_2'),\n",
    "            tf.keras.layers.Dense(15, activation='softmax', name='dense_3')\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.Accuracy(),\n",
    "                tf.keras.metrics.Precision(),\n",
    "                tf.keras.metrics.Recall(),\n",
    "                tf.keras.metrics.AUC()\n",
    "            ]\n",
    "        )\n",
    "        self.trained_model_arch = model.to_json() \n",
    "        print(\"Global Model Arch Sent\")\n",
    "        self.trained_model = model \n",
    "        ##### send model weights for first time \n",
    "        model.save_weights('./model.weights.h5')\n",
    "        cid = ip.publish('./model.weights.h5')\n",
    "        print(f\"Model weights cid {cid}\" )\n",
    "        ml_contract.functions.setGlobalModel(cid).transact({'from':w3.eth.accounts[0]})\n",
    "        print(\"Global Model Weights Sent\")\n",
    "\n",
    "    def Add_clients(self) : \n",
    "        for i,data_index in enumerate(self.user_id):\n",
    "            tx_hash = ml_contract.functions.addClient(data_index).transact({'from':w3.eth.accounts[0]})  # Use user_id[i] for address\n",
    "            print(f'Client {data_index} Added Succefully')\n",
    "\n",
    "    def scale_model_weights(self, weight, scalar):\n",
    "        '''function for scaling a models weights'''\n",
    "        weight_final = []\n",
    "        steps = len(weight)\n",
    "        for i in range(steps):\n",
    "            weight_final.append(scalar * weight[i])\n",
    "        return weight_final\n",
    "\n",
    "\n",
    "\n",
    "    def sum_scaled_weights(self, scaled_weight_list):\n",
    "        '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "        avg_grad = list()\n",
    "        #get the average grad accross all client gradients\n",
    "        for grad_list_tuple in zip(*scaled_weight_list):\n",
    "            layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "            avg_grad.append(layer_mean)\n",
    "        return avg_grad\n",
    "\n",
    "    def validate(self):\n",
    "        ####################################################\n",
    "        ############ Calculate Model Accureacy #############\n",
    "        print(\" Validating Global Model\")\n",
    "        self.preprocess()\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "        predictions  = self.trained_model.predict(self.x_test_user)    \n",
    "        # Convert y_test_user and predictions to class indices\n",
    "        true_classes = tf.argmax(self.y_test_user, axis=1).numpy()  # Convert to numpy for scikit-learn\n",
    "        predicted_classes = tf.argmax(predictions, axis=1).numpy()  # Convert to numpy for scikit-learn\n",
    "        \n",
    "        # Calculate precision and recall\n",
    "        precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "        recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "        accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "        auc = roc_auc_score(self.y_test_user, predictions, average='weighted', multi_class='ovr')\n",
    "\n",
    "        print(f'Precision: {precision}  , Recall: {recall},   AUC: {auc} , Acuracy :{accuracy}')\n",
    "\n",
    "        print(\"Finished\")\n",
    "        return {'AUC':auc, \"Precision\":precision, \"Recall\":recall, \"Accuracy\":accuracy }\n",
    "\n",
    "    def send_model_hash(self):\n",
    "        \n",
    "        ################################\n",
    "        ##### save model weights ####### \n",
    "        self.trained_model.save_weights(f'./tmp/global_add{self.epoch}.weights.h5')\n",
    "        print(\"wieghtd  \",f'./tmp/global_add{self.epoch}.weights.h5')\n",
    "        ################################\n",
    "        ##### send model hash ##########\n",
    "        cid = ip.publish(f'./tmp/global_add{self.epoch}.weights.h5')\n",
    "        print(cid)\n",
    "        ml_contract.functions.setGlobalModel( cid).transact({'from':w3.eth.accounts[0]})\n",
    "        #### Remove weights \n",
    "        os.remove(f'./tmp/global_add{self.epoch}.weights.h5')\n",
    "    \n",
    "    def Start_train(self):\n",
    "        Total_dataset = 0 \n",
    "        scaled_weights = []\n",
    "        ###########################################\n",
    "        ######### Clear Flag before start##########\n",
    "        # for i in range(len(self.user_id)):\n",
    "        #     ml_contract.functions.clearNewModelReady(i).transact({'from':w3.eth.accounts[0]})\n",
    "        ml_contract.functions.setIsStartTraining(False).transact({'from':w3.eth.accounts[0]})\n",
    "        ###########################################\n",
    "        ######### Define model Arch ###############\n",
    "        self.Model_Arch() \n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #### Send model arch as Json############### \n",
    "        ml_contract.functions.sendModelArch(json.dumps(self.trained_model_arch)).transact({'from':w3.eth.accounts[0]})\n",
    "\n",
    "        ###########################################\n",
    "        #### Add Clients To System ################ \n",
    "        self.Add_clients()\n",
    "\n",
    "        ml_contract.functions.setTrainLoop(True).transact({'from':w3.eth.accounts[0]})\n",
    "        \n",
    "        model_state = []\n",
    "\n",
    "        # ml_contract.functions.setTrainLoop(True).transact({'from':w3.eth.accounts[0]})\n",
    "\n",
    "\n",
    "        for i in range(self.epoch) :\n",
    "\n",
    "            print(\"#################################################\")\n",
    "     \n",
    "            ###########################################\n",
    "            ######### Start Clients training ########## \n",
    "            ml_contract.functions.setIsStartTraining(True).transact({'from':w3.eth.accounts[0]})\n",
    "            \n",
    "            \n",
    "            ###########################################\n",
    "            #### Loop throw All Client to get there results\n",
    "            # Initialize a set to keep track of ready clients\n",
    "            ready_clients_set = set()\n",
    "            ready_clients_set.clear()\n",
    "            while len(ready_clients_set) < len(self.user_id):\n",
    "                time.sleep(2)\n",
    "                print(f'Waiting {len(self.user_id) - len(ready_clients_set)} Clients to be ready')\n",
    "                \n",
    "                # Loop through each client\n",
    "                for i in range(len(self.user_id)):\n",
    "                    # Check if the client is ready and has not been counted yet\n",
    "                    if ml_contract.functions.clients(i).call()[2] and i not in ready_clients_set:\n",
    "                        print(f\"Client {self.user_id} with index {i} Finished Training\")\n",
    "                        ready_clients_set.add(i)\n",
    "            ###### Exit loop when all clients finish there training \n",
    "            ###########################################\n",
    "            # for i in range(len(self.user_id)):\n",
    "                # ml_contract.functions.clearNewModelReady(i).transact({'from':w3.eth.accounts[0]})\n",
    "\n",
    "            \n",
    "\n",
    "            ######### Start Clients training ########## \n",
    "            ml_contract.functions.setIsStartTraining(False).transact({'from':w3.eth.accounts[0]})\n",
    "    \n",
    "            ###########################################\n",
    "            #### Get data len to be weighted model##### \n",
    "                \n",
    "            Total_dataset = ml_contract.functions.sumDataLen().call()\n",
    "            print(\"Total Dataset Size ---> \",Total_dataset)\n",
    "    \n",
    "            ####################################################\n",
    "            ###### downlaod models Weights from ipfs \n",
    "            ## Loop throw all clients and download it is weights \n",
    "            ####################################################\n",
    "            for i in range(len(self.user_id)) : \n",
    "    \n",
    "                #### Get cid\n",
    "                cid = ml_contract.functions.getModelHash(i).call()\n",
    "                # if os.path.exists(f'./tmp/{cid}'):\n",
    "                #     os.remove(f'./tmp/{cid}')\n",
    "                print(cid)\n",
    "                # cid = 'QmYxh2Fet6FjA86PZQbfdoSG9xbiMYTmhTRrQi5iPuZ4R4'\n",
    "                ip.download(cid,'./tmp/')\n",
    "                if os.path.exists(f'./tmp/x{i}.weights.h5'):\n",
    "                    os.remove(f'./tmp/x{i}.weights.h5')\n",
    "                ### Load  file \n",
    "                os.rename(f'./tmp/{cid}', f'./tmp/x{i}.weights.h5')\n",
    "                self.trained_model.load_weights(f'./tmp/x{i}.weights.h5')\n",
    "                #remove file after loading it \n",
    "                # os.remove(f'./tmp/{cid}')\n",
    "                os.remove(f'./tmp/x{i}.weights.h5')\n",
    "                # ml_contract.functions.\n",
    "                \n",
    "                ####################################################\n",
    "                ############### Calculate scale #################### \n",
    "                # print(type(self.trained_model.weights))\n",
    "                scale = ml_contract.functions.getDataLen(i).call() / Total_dataset\n",
    "                w = self.trained_model.get_weights()\n",
    "                # print(len(w))\n",
    "    \n",
    "                ####################################################\n",
    "                #### Scale each model weight and save it############ \n",
    "                new_weight = self.scale_model_weights(w,scale )\n",
    "                scaled_weights.append(new_weight)\n",
    "                ml_contract.functions.clearNewModelReady(i).transact({'from':w3.eth.accounts[0]})\n",
    "                print(\"Wainting Clients to Finish Training\")\n",
    "            ####################################################    \n",
    "            ############### Aggregate weights ##################\n",
    "            average_weights = self.sum_scaled_weights(scaled_weights)\n",
    "    \n",
    "            ####################################################\n",
    "            ############## update global model ################# \n",
    "            self.trained_model.set_weights(average_weights)\n",
    "            self.send_model_hash()\n",
    "            \n",
    "\n",
    "            model_state.append(self.validate())     \n",
    "        ml_contract.functions.setTrainLoop(False).transact({'from':w3.eth.accounts[0]})\n",
    "\n",
    "            \n",
    "        \n",
    "        return model_state\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4bc9571-a79a-439d-bdba-46fd0979a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Connect Ganache endpoint\n",
    "w3 = web3.Web3(web3.HTTPProvider('http://127.0.0.1:7545'))\n",
    "##\n",
    "user_id = ['192.168.0.101',  '0' ]\n",
    "\n",
    "### Contract Address\n",
    "contract_address = '0x1c54d379603F38986B9c6c2F8216076F4324e24d'\n",
    "######\n",
    "abi = '[{\"constant\":true,\"inputs\":[],\"name\":\"loop\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"serverNewModel\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"isStartTraining\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"model_architecture\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"clientCount\",\"outputs\":[{\"name\":\"\",\"type\":\"uint256\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"\",\"type\":\"address\"}],\"name\":\"addressToIndex\",\"outputs\":[{\"name\":\"\",\"type\":\"uint256\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"\",\"type\":\"uint256\"}],\"name\":\"clients\",\"outputs\":[{\"name\":\"client_index\",\"type\":\"uint256\"},{\"name\":\"new_model_hash\",\"type\":\"string\"},{\"name\":\"new_model_ready\",\"type\":\"bool\"},{\"name\":\"data_index\",\"type\":\"string\"},{\"name\":\"data_len\",\"type\":\"uint256\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_state\",\"type\":\"bool\"}],\"name\":\"setTrainLoop\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[],\"name\":\"getTrainLoop\",\"outputs\":[{\"name\":\"loop\",\"type\":\"bool\"}],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"model\",\"type\":\"string\"}],\"name\":\"setGlobalModel\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[],\"name\":\"getGlobalModel\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_data_index\",\"type\":\"string\"}],\"name\":\"addClient\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"clientIndex\",\"type\":\"uint256\"},{\"name\":\"newDataLen\",\"type\":\"uint256\"}],\"name\":\"setDataLen\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"clientIndex\",\"type\":\"uint256\"}],\"name\":\"getDataLen\",\"outputs\":[{\"name\":\"\",\"type\":\"uint256\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"sumDataLen\",\"outputs\":[{\"name\":\"\",\"type\":\"uint256\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"clientIndex\",\"type\":\"uint256\"},{\"name\":\"modelHash\",\"type\":\"string\"}],\"name\":\"SetModelHash\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"clientIndex\",\"type\":\"uint256\"}],\"name\":\"getModelHash\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"clientIndex\",\"type\":\"uint256\"},{\"name\":\"newModel\",\"type\":\"string\"}],\"name\":\"updateModel\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"jsonString\",\"type\":\"string\"}],\"name\":\"sendModelArch\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"getModelArch\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_start\",\"type\":\"bool\"}],\"name\":\"setIsStartTraining\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"getIsStartTraining\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"stateMutability\":\"view\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"clientIndex\",\"type\":\"uint256\"}],\"name\":\"setNewModelReady\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"clientIndex\",\"type\":\"uint256\"}],\"name\":\"clearNewModelReady\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"}]'\n",
    "\n",
    "ml_contract = w3.eth.contract(abi=abi, address=contract_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c642cd3f-bfca-468c-9c2f-10e09433e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Path \n",
    "epoch = 10\n",
    "data_path = './Cleaned_data.csv'\n",
    "\n",
    "test = Server(user_id,data_path,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778807fe-8a22-40a8-9cbf-303bfcb65877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mStart_train()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "state = test.Start_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0dac4a-a8fc-47e8-8815-df0417c3402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(state)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f968ad-46db-4cdf-a6c8-d4f36e91dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_id)):\n",
    "    ml_contract.functions.clearNewModelReady(i).transact({'from':w3.eth.accounts[0]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0692e6-a7de-430d-ab91-030b6429fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(ml_contract.functions.clients(i).call())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c9d15-b0fd-411a-b64b-1c94786c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_id)) : \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908c79a-2d79-49f2-b9ba-a6cb3c4e8d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
